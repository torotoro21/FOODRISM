{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = os.getcwd()\n",
    "source_dataset = os.path.join(source_path, 'dataset')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.path.join(source_path, 'images')\n",
    "training_dir = os.path.join(images, 'train')\n",
    "testing_dir = os.path.join(images, 'test')\n",
    "def create_dir(sourcepath):\n",
    "    os.makedirs(images)\n",
    "    os.makedirs(training_dir)\n",
    "    os.makedirs(testing_dir)\n",
    "\n",
    "try:\n",
    "    create_dir(images)\n",
    "except FileExistsError:\n",
    "    print(\"file already exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = .8\n",
    "def split_data(source, training, testing, split_size):\n",
    "  files = []\n",
    "  for filename in os.listdir(source):\n",
    "    file = source + filename\n",
    "    files.append(filename)\n",
    "\n",
    "  trainlen = int(len(files)/2 * split_size)\n",
    "  testlen = int(len(files)/2 - trainlen)\n",
    "  \n",
    "  training_content = files[0:trainlen]\n",
    "  testing_content = files[-testlen:]\n",
    "\n",
    "  for filename in training_content:\n",
    "    sources = source + filename\n",
    "    destination = training + filename\n",
    "    copyfile(sources, destination)\n",
    "\n",
    "  for filename in testing_content:\n",
    "    sources = source + filename\n",
    "    destination = testing + filename\n",
    "    copyfile(sources, destination)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(source_dataset):\n",
    "    dirs = (os.path.join(source_dataset, i + '/'))\n",
    "    train_dest = (os.path.join(training_dir + '/'))\n",
    "    test_dest = (os.path.join(testing_dir + '/'))\n",
    "    split_data(dirs, train_dest, test_dest, split_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING LABEL MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "files = {\n",
    "    \n",
    "    'LABELMAP': os.path.join(source_path, 'data', LABEL_MAP_NAME)\n",
    "}\n",
    "\n",
    "labels = [{'name':'pecel', 'id':1}, {'name':'sate', 'id':2}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ede63c295133f3d2c514627e4f3d992b09efdc78e31bb60e1108a9531bf0af46"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tfod')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
