{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = os.getcwd()\n",
    "source_dataset = os.path.join(source_path, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = os.path.join(source_path, 'training')\n",
    "testing_dir = os.path.join(source_path, 'testing')\n",
    "def create_dir(sourcepath):\n",
    "    training = os.path.join(source_path, 'training')\n",
    "    testing = os.path.join(source_path, 'testing')\n",
    "    os.makedirs(training)\n",
    "    os.makedirs(testing)\n",
    "    #creating training & testing dir\n",
    "    for file in os.listdir(source_dataset):\n",
    "        training_dir = os.makedirs(os.path.join(training, file))\n",
    "        testing_test = os.makedirs(os.path.join(testing, file))\n",
    "\n",
    "try:\n",
    "    create_dir(source_path)\n",
    "except FileExistsError:\n",
    "    print(\"file already exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = .8\n",
    "def split_data(source, training, testing, split_size):\n",
    "  files = []\n",
    "  for filename in os.listdir(source):\n",
    "    file = source + filename\n",
    "    \"\"\"if os.path.getsize(file) > 0:\"\"\"\n",
    "    files.append(filename)\n",
    "\n",
    "  trainlen = int(len(files) * split_size)\n",
    "  testlen = int(len(files) - trainlen)\n",
    "  ramdomize = random.sample(files, len(files))\n",
    "  training_content = ramdomize[0:trainlen]\n",
    "  testing_content = ramdomize[-testlen:]\n",
    "\n",
    "  for filename in training_content:\n",
    "    sources = source + filename\n",
    "    destination = training + filename\n",
    "    copyfile(sources, destination)\n",
    "\n",
    "  for filename in testing_content:\n",
    "    sources = source + filename\n",
    "    destination = testing + filename\n",
    "    copyfile(sources, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(source_dataset):\n",
    "    dirs = (os.path.join(source_dataset, i + '/'))\n",
    "    train_dest = (os.path.join(training_dir, i + '/'))\n",
    "    test_dest = (os.path.join(testing_dir, i + '/'))\n",
    "    #print(test_dest)\n",
    "    split_data(dirs, train_dest, test_dest, split_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5525f8f2375eeb3e84b059d1498aafdb86623e263678a1541caa83f98b7e9e56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
