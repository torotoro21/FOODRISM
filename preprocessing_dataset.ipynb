{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = os.getcwd()\n",
    "source_dataset = os.path.join(source_path, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'd:\\\\BANGKIT\\\\CAPSTONE PROJECT\\\\FOODRISM\\\\training\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\BANGKIT\\CAPSTONE PROJECT\\FOODRISM\\preprocessing_dataset.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=6'>7</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(testing)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=8'>9</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(training, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=10'>11</a>\u001b[0m create_dir(source_path)\n",
      "\u001b[1;32md:\\BANGKIT\\CAPSTONE PROJECT\\FOODRISM\\preprocessing_dataset.ipynb Cell 6'\u001b[0m in \u001b[0;36mcreate_dir\u001b[1;34m(sourcepath)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=5'>6</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(training)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(testing)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000005?line=8'>9</a>\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(training, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\tf-gpu\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=222'>223</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=223'>224</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=224'>225</a>\u001b[0m     mkdir(name, mode)\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=225'>226</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=226'>227</a>\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=227'>228</a>\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/os.py?line=228'>229</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'd:\\\\BANGKIT\\\\CAPSTONE PROJECT\\\\FOODRISM\\\\training\\\\'"
     ]
    }
   ],
   "source": [
    "training = os.path.join(source_path, 'training')\n",
    "testing = os.path.join(source_path, 'testing')\n",
    "def create_dir(sourcepath):\n",
    "    training = os.path.join(source_path, 'training')\n",
    "    testing = os.path.join(source_path, 'testing')\n",
    "    os.makedirs(training)\n",
    "    os.makedirs(testing)\n",
    "\n",
    "    os.makedirs(os.path.join(training, ''))\n",
    "\n",
    "create_dir(source_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bika Ambon', 'Gudeg', 'Gulai_ayam', 'Kerak telor', 'klepon', 'martabak', 'Nasi Tumpeng', 'pecel', 'pempek', 'Rawon', 'Rendang', 'sate', 'Serabi', 'Soto Ayam', 'tahu_gejrot']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(source_dataset))\n",
    "training = os.path.join(source_path, 'training')\n",
    "testing = os.path.join(source_path, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training & testing dir\n",
    "\n",
    "for file in os.listdir(source_dataset):\n",
    "    \n",
    "    training_dir = os.makedirs(os.path.join(training, file))\n",
    "    testing_test = os.makedirs(os.path.join(testing, file))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_withmask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\BANGKIT\\CAPSTONE PROJECT\\FOODRISM\\preprocessing_dataset.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000008?line=25'>26</a>\u001b[0m     destination \u001b[39m=\u001b[39m TESTING \u001b[39m+\u001b[39m filename\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000008?line=26'>27</a>\u001b[0m     copyfile(source, destination)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000008?line=28'>29</a>\u001b[0m split_data(source_withmask, dest_train_mask, dest_testing_mask, split_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source_withmask' is not defined"
     ]
    }
   ],
   "source": [
    "split_size = 0.8\n",
    "files = []\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "  files = []\n",
    "  for filename in os.listdir(SOURCE):\n",
    "    file = SOURCE + filename\n",
    "    if os.path.getsize(file) > 0:\n",
    "      files.append(filename)\n",
    "    else:\n",
    "      print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "  #declare length file & randomize\n",
    "  trainlen = int(len(files) * SPLIT_SIZE)\n",
    "  testlen = int(len(files) - trainlen)\n",
    "  randomm = random.sample(files, len(files))\n",
    "  training_content = randomm[0:trainlen]\n",
    "  testing_content = randomm[-testlen:]\n",
    "\n",
    "  #copying\n",
    "  for filename in training_content:\n",
    "    source = SOURCE + filename\n",
    "    destination = TRAINING + filename\n",
    "    copyfile(source, destination)\n",
    "  for filename in testing_content:\n",
    "    source = SOURCE + filename\n",
    "    destination = TESTING + filename\n",
    "    copyfile(source, destination)\n",
    "\n",
    "split_data(source_withmask, dest_train_mask, dest_testing_mask, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\BANGKIT\\CAPSTONE PROJECT\\FOODRISM\\preprocessing_dataset.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(source_dataset):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000010?line=1'>2</a>\u001b[0m     source \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(source_dataset, file))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/BANGKIT/CAPSTONE%20PROJECT/FOODRISM/preprocessing_dataset.ipynb#ch0000010?line=2'>3</a>\u001b[0m     destination \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(training_dir, file)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\tf-gpu\\lib\\ntpath.py:78\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/ntpath.py?line=76'>77</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(path, \u001b[39m*\u001b[39mpaths):\n\u001b[1;32m---> <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/ntpath.py?line=77'>78</a>\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(path)\n\u001b[0;32m     <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/ntpath.py?line=78'>79</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m     <a href='file:///d%3A/anaconda/envs/tf-gpu/lib/ntpath.py?line=79'>80</a>\u001b[0m         sep \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(source_dataset):\n",
    "    source = os.listdir(os.path.join(source_dataset, file))\n",
    "    destination = os.path.join(training_dir, file)\n",
    "    #print(os.listdir(source)[:41])\n",
    "    #copyfile((source, destination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5525f8f2375eeb3e84b059d1498aafdb86623e263678a1541caa83f98b7e9e56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
