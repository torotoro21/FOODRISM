{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = os.getcwd()\n",
    "source_dataset = os.path.join(source_path, 'dataset')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = os.path.join(os.getcwd(), 'train')\n",
    "testing_dir = os.path.join(os.getcwd(), 'test')\n",
    "def create_dir(sourcepath):\n",
    "    os.makedirs(training_dir)\n",
    "    os.makedirs(testing_dir)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in os.listdir(source_dataset):\n",
    "        os.makedirs(os.path.join(training_dir, i))\n",
    "\n",
    "    for i in os.listdir(source_dataset):\n",
    "        os.makedirs(os.path.join(testing_dir, i))\n",
    "except FileExistsError:\n",
    "    print(\"file already exist\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = .8\n",
    "def split_data(source, training, testing, split_size):\n",
    "  files = []\n",
    "  for filename in os.listdir(source):\n",
    "    file = source + filename\n",
    "    files.append(filename)\n",
    "\n",
    "  trainlen = int(len(files) * split_size)\n",
    "  testlen = int(len(files) - trainlen)\n",
    "  ramdomize = random.sample(files, len(files))\n",
    "  training_content = ramdomize[0:trainlen]\n",
    "  testing_content = ramdomize[-testlen:]\n",
    "\n",
    "  for filename in training_content:\n",
    "    sources = source + filename\n",
    "    destination = training + filename\n",
    "    copyfile(sources, destination)\n",
    "\n",
    "  for filename in testing_content:\n",
    "    sources = source + filename\n",
    "    destination = testing + filename\n",
    "    copyfile(sources, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n",
      "file already exist\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(source_dataset):\n",
    "    dirs = (os.path.join(source_dataset, i + '/'))\n",
    "    train_dest = (os.path.join(training_dir, i + '/'))\n",
    "    test_dest = (os.path.join(testing_dir, i + '/'))\n",
    "    #print(test_dest)\n",
    "    split_data(dirs, train_dest, test_dest, split_size)\n",
    "    try:\n",
    "        create_dir(source_path)\n",
    "    except FileExistsError:\n",
    "        print(\"file already exist\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ede63c295133f3d2c514627e4f3d992b09efdc78e31bb60e1108a9531bf0af46"
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
